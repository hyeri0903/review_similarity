{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.utils import pprint\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter=Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # 소수점 아래 3자리까지 나타내기, 4째자리에서 반올림\n",
    "def short_float(val):\n",
    "    value = float(\"{:.4f}\".format(val))\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_group(title, groups, used_func):\n",
    "    pivot_num = 0.1\n",
    "    save_list = list()\n",
    "\n",
    "    pprint(title)\n",
    "    cur_num = 0.0\n",
    "    for i, group in enumerate(groups):\n",
    "        save_list.append(used_func(group))\n",
    "        print('group ' + str(i + 1) + ' = ' + str(float(\"{:.1f}\".format(cur_num))) + str(' over ') + str(\n",
    "            float(\"{:.1f}\".format(cur_num + pivot_num))) + str(' under : '), save_list[i])\n",
    "        cur_num += pivot_num\n",
    "    print('\\n')\n",
    "\n",
    "    return save_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer : 문장에서 색인어 추출을 위해 정해진 품사의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def token(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\",\"Adjective\",\"KoreanParticle\",\n",
    "                        \"Punctuation\",\"Determiner\", \"Adverb\", \"Conjunction\",\"Excalmation\", \"Foreign\"], stopword=[]):\n",
    "    return [\n",
    "        word for word, tag in twitter.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "        \n",
    "          if len(word) >=1 and tag in pos and word not in stopword\n",
    "\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorize= TfidfVectorizer(\n",
    "    tokenizer=token,\n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "#reviewer의 desc를 담는 리스트\n",
    "def make_reviews(cid):\n",
    "    desc=(go_data.loc[go_data['cId']==cid])['desc']\n",
    "    desc=list(desc)\n",
    "    \n",
    "    return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. 리뷰들을 tf-idf 적용하여 벡터화\n",
    "def tfidf(desc):\n",
    "    X = vectorize.fit_transform(desc)\n",
    "    print('fit_transform, (No.review {}, feature {})'.format(X.shape[0], X.shape[1]))\n",
    "    features = vectorize.get_feature_names()\n",
    "    \n",
    "    print (pd.DataFrame(data=X.toarray(), columns=features))\n",
    "    vector_array=X.toarray()\n",
    "    \n",
    "    return vector_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. 유사도 구하기222222222\n",
    "def similarity(vector_arr,desc):   \n",
    "    sm=[] #한 리뷰어의 리뷰 유사도를 담을 리스트\n",
    "    max_cnt=0 #리뷰 유사도 최대값이 0.9 이상 count\n",
    "    _sum=0\n",
    "    _mid=0\n",
    "    cnt=0\n",
    "    for i in range(len(desc)-1):\n",
    "        srch_vector= vectorize.transform([desc[i]])\n",
    "        for j in range(i+1, len(desc)):\n",
    "            cosine_similar =cosine_similarity(srch_vector, [vector_arr[j]]).flatten()\n",
    "            cosine_similar=short_float(float(cosine_similar))\n",
    "          #  print (\"cosine_similar \") + str(i+1) + str(' 번째 리뷰와') + str(j+1) + str(' 번째 리뷰 : ') + str(cosine_similar)\n",
    "            sm.append(cosine_similar)\n",
    "\n",
    "\n",
    "   # pprint(u'유사도 리스트'),;print (sm)\n",
    "\n",
    "    sm.sort(reverse=True)\n",
    "    _min=min(sm)\n",
    "    _mid=statistics.median(sm) # 유사도의 중간값\n",
    "    _max=max(sm)\n",
    "    _sum=sum(sm)\n",
    "\n",
    "    if(_max>=0.9):\n",
    "        max_cnt+=1\n",
    "        \n",
    "    avg= short_float(_sum/len(sm))\n",
    "    \n",
    "    \n",
    "  #  print ('min : ', _min)\n",
    "  #  print ('mid : ', _mid)\n",
    "  #  print('max : ', _max)\n",
    "    print('avg : ', avg)\n",
    "   # print('num of 1 : ', cnt)\n",
    "    print('# similarity over 0.9 : ', max_cnt)\n",
    "    \n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_want_val(sm_list,used_func):\n",
    "    val=(used_func(sm_list))\n",
    "   \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_groups(_list):\n",
    "    group1=0\n",
    "    group2=0\n",
    "    group3=0\n",
    "    group4=0\n",
    "    group5=0\n",
    "    group6=0\n",
    "    group7=0\n",
    "    group8=0\n",
    "    group9=0\n",
    "    group10=0\n",
    "    \n",
    "    for i in range(len(_list)):\n",
    "        if(_list[i]<0.1):\n",
    "            group1+=1\n",
    "        elif(_list[i]>=0.1 and _list[i]< 0.2):\n",
    "            group2+=1\n",
    "        elif(_list[i] >=0.2 and _list[i]< 0.3):\n",
    "            group3+=1\n",
    "        elif(_list[i] >=0.3 and _list[i]< 0.4):\n",
    "            group4+=1\n",
    "        elif(_list[i]>=0.4 and _list[i]< 0.5):\n",
    "            group5+=1\n",
    "        elif(_list[i]>=0.5 and _list[i] < 0.6):\n",
    "            group6+=1\n",
    "        elif(_list[i]>=0.6 and _list[i] < 0.7):\n",
    "            group7+=1\n",
    "        elif(_list[i]>=0.7 and _list[i]< 0.8):\n",
    "            group8+=1\n",
    "        elif(_list[i]>=0.8 and _list[i]< 0.9):\n",
    "            group9+=1\n",
    "        elif(_list[i]>=0.9):\n",
    "            group10+=1\n",
    "        \n",
    "    groups=[group1, group2, group3, group4, group5, group6,group7,group8,group9,group10 ]\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_list=[]\n",
    "mid_list=[]\n",
    "q1_list=[]\n",
    "q3_list=[]\n",
    "\n",
    "for i in range(len(spammer)):\n",
    "    print str(i+1) + str('번째 리뷰어: ')+ str(spammer[i])\n",
    "    reviews=make_reviews(spammer[i])\n",
    "    if(len(reviews)<2):\n",
    "        continue\n",
    "    vector_array=tfidf(reviews)\n",
    "    sm=similarity(vector_array, reviews)\n",
    "\n",
    "  \n",
    "    result_max= print_want_val(sm, lambda x: np.percentile(sm,100)) # 최대값 반환 \n",
    "    print (\"max: \", result_max)\n",
    "    max_list.append(result_max)\n",
    "    \n",
    "    result_mid = print_want_val(sm, lambda x: np.percentile(sm,50)) # 중간값 반환 \n",
    "    print (\"median: \", result_mid)\n",
    "    mid_list.append(result_mid)\n",
    "    \n",
    "    result_q1 = print_want_val(sm, lambda x: np.percentile(sm,25)) # 상위 75%\n",
    "    print(\"1st quartile: \", result_q1)\n",
    "    q1_list.append(result_q1)\n",
    "    \n",
    "    result_q3 = print_want_val(sm, lambda x: np.percentile(sm,75)) #상위 25%\n",
    "    print(\"3rd quartile: \", result_q3)         \n",
    "    q3_list.append(result_q3)\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    \n",
    "groups_max=make_groups(max_list)\n",
    "groups_mid=make_groups(mid_list)\n",
    "groups_q1=make_groups(q1_list)\n",
    "groups_q3=make_groups(q3_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
